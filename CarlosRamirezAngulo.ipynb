{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "97ca9aaf",
      "metadata": {
        "id": "97ca9aaf"
      },
      "source": [
        "# <font color=\"blue\"> MSc em Ciência de Dados</font>\n",
        "# <font color=\"blue\">Avaliação Final PCD TACTD</font>\n",
        "\n",
        "**Produzido por Carlos Ramirez Angulo**<br>\n",
        "**Cemeai - ICMC/USP - São Carlos**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3e2d921",
      "metadata": {
        "id": "a3e2d921"
      },
      "source": [
        "Considere o conteúdo contido no link abaixo:\n",
        "\n",
        "[https://lite.cnn.com/2024/01/10/investing/sec-hack-bitcoin-etf/index.html]('https://lite.cnn.com/2024/01/10/investing/sec-hack-bitcoin-etf/index.html')\n",
        "\n",
        "Tal conteúdo corresponde a um arquivo html contendo uma notícia sobre uma possível fraude no marcado de bitcoins. Cada parágrafo da notícia está marcado no arquivo html pela tag:\n",
        "\n",
        "```html\n",
        "<p class=\"paragraph--lite\">\n",
        "    parágrafo da notícia...\n",
        "</p>\n",
        "```\n",
        "\n",
        "1. Faça uma requisição ao site cujo link é dado acima e armazenar o conteúdo (arquivo html) em uma string.\n",
        "\n",
        "2. Faça um parser no html para extrair apenas os parágrafos da notícia, armazenando o texto extraído em uma única string.\n",
        "\n",
        "3. Extraia da string obtida no item 2 as palavras que:\n",
        "    - contenham mais que **2** caracteres,\n",
        "    - sejam constituídas apenas por letras do alfabeto e\n",
        "    - não sejam 'stop words'.\n",
        "Armazene as palavras obtidas em uma lista.\n",
        "\n",
        "5. Aplique uma normalização léxica na lista de palavras obtidas no item 3 e calcule a frequência com que cada palavra lexicamente normalizada aparece na lista. Armazene o resultado em um dicionário cujas chaves são as palavras e os valores a frequência da palavra correspondente.\n",
        "\n",
        "6. Encontre as palavras cujas frequências são outliers, como sendo as que superam um limiar de 3 vezes o desvio padrão das frequências.\n",
        "\n",
        "Com base nos itens acima, assinale a alternativa correta:\n",
        "\n",
        "\n",
        "a) Número de palavras contidas na lista obtida no item 3 --> 286 <br>\n",
        "&nbsp;&nbsp;&nbsp; Número de palavras com frequência igual a 1 no dicionário do item 4 --> 147 <br>\n",
        "&nbsp;&nbsp;&nbsp; Número de palavras com frequência considerada outlier --> 10<br>\n",
        "\n",
        "b) Número de palavras contidas na lista obtida no item 3 --> 134 <br>\n",
        "&nbsp;&nbsp;&nbsp; Número de palavras com frequência igual a 1 no dicionário do item 4 --> 47 <br>\n",
        "&nbsp;&nbsp;&nbsp; Número de palavras com frequência considerada outlier --> 18\n",
        "\n",
        "c) Número de palavras contidas na lista obtida no item 3 --> 392 <br>\n",
        "&nbsp;&nbsp;&nbsp; Número de palavras com frequência igual a 1 no dicionário do item 4 --> 99 <br>\n",
        "&nbsp;&nbsp;&nbsp; Número de palavras com frequência considerada outlier --> 5\n",
        "\n",
        "d) Número de palavras contidas na lista obtida no item 3 --> 531 <br>\n",
        "&nbsp;&nbsp;&nbsp; Número de palavras com frequência igual a 1 no dicionário do item 4 --> 231 <br>\n",
        "&nbsp;&nbsp;&nbsp; Número de palavras com frequência considerada outlier --> 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8c2d6e4",
      "metadata": {
        "id": "a8c2d6e4"
      },
      "outputs": [],
      "source": [
        "import requests as rq\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "import numpy as np\n",
        "from bs4 import BeautifulSoup\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# downloads\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8JhBKuC2bs8",
        "outputId": "92b19461-acb6-4728-af95-3deec3590b31"
      },
      "id": "R8JhBKuC2bs8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c653f23",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c653f23",
        "outputId": "c81364f6-ee1a-48d1-94fe-92556832a075"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n"
          ]
        }
      ],
      "source": [
        "# Opcional: verifique se a API do site está responsiva e verificando o tipo de conteúdo\n",
        "# ...\n",
        "\n",
        "url = \"https://lite.cnn.com/2024/01/10/investing/sec-hack-bitcoin-etf/index.html\"\n",
        "\n",
        "pagina_head = rq.head(url)\n",
        "print(pagina_head.status_code)\n",
        "# ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5760ec9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5760ec9",
        "outputId": "563a42f1-b023-4736-a515-26870d36db5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  <!DOCTYPE html>\n",
            "<html lang=\"en\" data-layout-uri=\"cms.cnn.com/_layouts/layout-with-rail/instances/business-article-v1@published\">\n",
            "  <head><style>body,h1,h2,h3,h4,h5{font-family:cnn_sans_display,helve\n"
          ]
        }
      ],
      "source": [
        "# Extrair o conteúdo da página como string\n",
        "\n",
        "pg = rq.get(url)\n",
        "texto = pg.text\n",
        "\n",
        "print(texto[:200])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9e222c0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9e222c0",
        "outputId": "64328a99-ea9e-4da8-fdc4-7ad7802ebbc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "  The Securities and Exchange Commission said Wednesday the FBI is investigating the hack of the agency’s social media account that rocked the bitcoin world earlier this week ahead of the regulator’\n"
          ]
        }
      ],
      "source": [
        "# Parsing do html para extrair somente o texto da notícia\n",
        "\n",
        "soup = BeautifulSoup(texto, 'html.parser')\n",
        "\n",
        "# soup\n",
        "\n",
        "texto_limpo = \"\"\n",
        "for evento in soup('p', {'class': 'paragraph--lite'}):\n",
        " data = evento.text\n",
        " texto_limpo = texto_limpo + ' ' + data\n",
        "\n",
        "print(texto_limpo[:200])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1700ae75",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1700ae75",
        "outputId": "8cc0d55f-598d-45d2-8b4b-e9995dc3239d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "179\n",
            "['secur', 'exchang', 'commiss', 'said', 'wednesday', 'fbi', 'investig', 'hack', 'agenc', 'social', 'media', 'account', 'rock', 'bitcoin', 'world', 'earlier', 'week', 'ahead', 'regul', 'approv', 'bitcoin', 'fund', 'late', 'wednesday', 'sec', 'continu', 'investig', 'matter', 'coordin', 'appropri', 'law', 'enforc', 'entiti', 'includ', 'sec', 'offic', 'inspector', 'gener', 'fbi', 'sec', 'spokesperson', 'said', 'statement', 'sec', 'said', 'unauthor', 'content', 'agenc', 'verifi', 'account', 'formerli', 'known', 'twitter', 'draft', 'creat', 'bitcoin', 'price', 'briefli', 'jump', 'tuesday', 'sec', 'account', 'post', 'messag', 'say', 'regul', 'approv', 'multipl', 'bitcoin', 'etf', 'sec', 'approv', 'highli', 'anticip', 'crypto', 'investor', 'would', 'help', 'bring', 'bitcoin', 'mainstream', 'make', 'easier', 'peopl', 'buy', 'one', 'crypto', 'exchang', 'coinbas', 'even', 'post', 'celebratori', 'messag', 'social', 'media', 'tuesday', 'howev', 'minut', 'later', 'sec', 'chair', 'gari', 'gensler', 'said', 'agenc', 'account', 'compromis', 'allow', 'unauthor', 'tweet', 'get', 'post', 'concern', 'unauthor', 'access', 'sec', 'account', 'could', 'undermin', 'market', 'agenc', 'mission', 'sherrod', 'brown', 'chairman', 'senat', 'bank', 'committe', 'said', 'statement', 'wednesday', 'brown', 'said', 'expect', 'sec', 'keep', 'committe', 'updat', 'encourag', 'offic', 'sec', 'inspector', 'gener', 'look', 'incid', 'well', 'republican', 'sen', 'vanc', 'thom', 'tilli', 'slam', 'sec', 'letter', 'gensler', 'wednesday', 'night', 'unaccept', 'agenc', 'entrust', 'regul', 'epicent', 'world', 'capit', 'market', 'would', 'make', 'coloss', 'error', 'wrote', 'fals', 'announc', 'could', 'huge', 'implic', 'etf', 'bitcoin', 'could', 'drive', 'much', 'billion', 'invest', 'year', 'approv', 'said', 'nick', 'smart', 'director', 'intellig', 'crystal', 'blockchain', 'bitcoin', 'digit', 'asset', 'experienc', 'signific', 'price', 'fluctuat', 'fake', 'messag', 'post', 'tuesday', 'bitcoin', 'price', 'shot', 'fall', 'news', 'cross', 'misinform', 'quickli', 'spread', 'across', 'variou', 'media', 'platform', 'wednesday', 'sec', 'releas', 'offici', 'decis', 'approv', 'etf', 'cryptocurr', 'rose', 'nearli', 'accord', 'data', 'spokesperson', 'later', 'said', 'sec', 'social', 'media', 'account', 'lack', 'basic', 'secur', 'measur', 'authent', 'rais', 'seriou', 'question', 'agenc', 'cybersecur', 'protocol', 'alleg', 'lack', 'secur', 'particularli', 'befuddl', 'given', 'sec', 'previou', 'rule', 'social', 'media', 'post', 'could', 'serv', 'public', 'announc', 'investor', 'financi', 'commun', 'close', 'monitor', 'sec', 'respons', 'breach', 'could', 'lead', 'signific', 'chang', 'financi', 'inform', 'dissemin', 'digit', 'age', 'addit', 'report', 'nicol', 'goodkind', 'see', 'full', 'web', 'articl']\n"
          ]
        }
      ],
      "source": [
        "# normalização lexica das palavras (STEM)\n",
        "\n",
        "stop_words = nltk.corpus.stopwords.words('english')\n",
        "print(len(stop_words))\n",
        "\n",
        "words = nltk.word_tokenize(texto_limpo)\n",
        "words = [w.lower() for w in words if w.isalpha() and len(w) > 2]\n",
        "words = [w for w in words if w not in stop_words]\n",
        "\n",
        "words = [PorterStemmer().stem(w) for w in words]\n",
        "print(words[:400])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIMkYQpk50H2",
        "outputId": "905ade2b-3363-4ae2-f73b-02657cac2404"
      },
      "id": "WIMkYQpk50H2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "286"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8940093",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8940093",
        "outputId": "1761c459-e731-4744-89b8-632c83c5a7fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('secur', 3), ('exchang', 2), ('commiss', 1), ('said', 8), ('wednesday', 5), ('fbi', 2), ('investig', 2), ('hack', 1), ('agenc', 6), ('social', 4)]\n"
          ]
        }
      ],
      "source": [
        "# calcular o dicionário de palavras:frequência\n",
        "\n",
        "dictionary= dict(Counter(words))\n",
        "print(list(dictionary.items())[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "578a0a0a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "578a0a0a",
        "outputId": "eac497ef-0c74-4bb1-b310-9297e99cec9f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "147"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# calcular o número de palavras com frequência 1 no dicionário\n",
        "\n",
        "single = [k for k, v in dictionary.items() if v == 1]\n",
        "len(single)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f51c69f4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f51c69f4",
        "outputId": "7acb27e7-95fc-447d-c24a-c324eb4645aa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# calcular a quantidade de frequencias outlier\n",
        "\n",
        "# Encontre as palavras cujas frequências são outliers,\n",
        "# como sendo as que superam um limiar de 3 vezes o desvio padrão das frequências.\n",
        "\n",
        "outliers = [k for k, v in dictionary.items() if v > np.std(list(dictionary.values())) * 3]\n",
        "len(outliers)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Outra forma de fazer\n",
        "std_freq = np.std(list(dictionary.values()))\n",
        "\n",
        "outlier_threshold = 3 * std_freq\n",
        "outlier_words = [word for word, freq in dictionary.items() if freq > outlier_threshold]\n",
        "\n",
        "# outlier_words\n",
        "len(outlier_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVsi1mnw46h1",
        "outputId": "c2c4346a-3877-4f5d-b72e-fc16b4dc82b2"
      },
      "id": "VVsi1mnw46h1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}